import sys
import os
from datetime import datetime, timedelta

# Ğ¢Ğ¾Ğ·Ğ¸ Ğ±Ğ»Ğ¾Ğº Ğ³Ğ°Ñ€Ğ°Ğ½Ñ‚Ğ¸Ñ€Ğ°, Ñ‡Ğµ Python Ğ½Ğ°Ğ¼Ğ¸Ñ€Ğ° Ğ¿Ğ°Ğ¿ĞºĞ° src
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(project_root)

# --- Ğ˜ĞœĞŸĞĞ Ğ¢Ğ˜ ---
from config import ASSETS_TO_TRACK
from src.database.database_manager import DatabaseManager
from src.data_ingestion.rss_client import fetch_rss_articles
from src.data_ingestion.newsapi_client import NewsApiClient
from src.data_ingestion.coingecko_client import CoinGeckoClient
from src.analysis.ai_analyzer import AIAnalyzer
from src.data_ingestion.kucoin_client import KucoinHandler
# --- Ğ”ĞĞ‘ĞĞ’Ğ¯ĞœĞ• Ğ˜ĞœĞŸĞĞ Ğ¢ Ğ—Ğ DEFI LLAMA ---
from src.data_ingestion.defillama_client import DefiLlamaHandler

# --- ĞšĞĞĞ¡Ğ¢ĞĞĞ¢Ğ˜ ---
ECONOMIC_NEWS_KEYWORDS = ['inflation', 'interest rate', 'GDP', 'FOMC', 'unemployment']


# --- Ğ”Ğ•Ğ¤Ğ˜ĞĞ˜Ğ¦Ğ˜Ğ˜ ĞĞ Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜Ğ¢Ğ• ---

def run_news_pipeline(db_manager: DatabaseManager, news_api_client: NewsApiClient):
    """Ğ˜Ğ·Ğ¿ÑŠĞ»Ğ½ÑĞ²Ğ° Ñ†ĞµĞ»Ğ¸Ñ Ğ¿Ñ€Ğ¾Ñ†ĞµÑ Ğ¿Ğ¾ ÑÑŠĞ±Ğ¸Ñ€Ğ°Ğ½Ğµ Ğ¸ Ğ·Ğ°Ğ¿Ğ°Ğ·Ğ²Ğ°Ğ½Ğµ Ğ½Ğ° Ğ½Ğ¾Ğ²Ğ¸Ğ½Ğ¸."""
    print("\n--- ğŸ“° STEP 1: COLLECTING NEWS ---")
    # ... (ĞºĞ¾Ğ´ÑŠÑ‚ Ñ‚ÑƒĞº Ğ¾ÑÑ‚Ğ°Ğ²Ğ° ÑÑŠÑ‰Ğ¸ÑÑ‚) ...
    rss_articles = fetch_rss_articles()
    asset_articles = news_api_client.fetch_asset_news()
    economic_articles = news_api_client.fetch_economic_news(ECONOMIC_NEWS_KEYWORDS)
    all_articles = rss_articles + asset_articles + economic_articles
    unique_articles = list({article['url']: article for article in all_articles if article.get('url')}.values())
    if unique_articles:
        rows_saved = db_manager.save_articles(unique_articles)
        print(f"ğŸ’¾ Found {len(unique_articles)} unique articles. Saved {rows_saved} new ones to the database.")

def run_ai_analysis_pipeline(db_manager: DatabaseManager, ai_analyzer: AIAnalyzer):
    """Ğ˜Ğ·Ğ¿ÑŠĞ»Ğ½ÑĞ²Ğ° Ğ¿Ñ€Ğ¾Ñ†ĞµÑĞ° Ğ¿Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ½Ğ° Ğ½Ğ¾Ğ²Ğ¸ ÑÑ‚Ğ°Ñ‚Ğ¸Ğ¸."""
    print("\n--- ğŸ§  STEP 2: RUNNING AI ANALYSIS ---")
    # ... (ĞºĞ¾Ğ´ÑŠÑ‚ Ñ‚ÑƒĞº Ğ¾ÑÑ‚Ğ°Ğ²Ğ° ÑÑŠÑ‰Ğ¸ÑÑ‚) ...
    unprocessed_articles = db_manager.get_unprocessed_articles(limit=30)
    if not unprocessed_articles:
        print("No new articles to analyze.")
        return
    print(f"Found {len(unprocessed_articles)} unprocessed articles. Starting AI analysis...")
    for article in unprocessed_articles:
        is_economic = article.get('category') == 'economic_event'
        analysis = ai_analyzer.analyze_article_title(article['title'], is_economic=is_economic)
        if analysis:
            db_manager.update_article_analysis(article['id'], analysis)
            print(f"   -> âœ… AI analysis for article #{article['id']} '{article['title'][:30]}...' saved.")

def run_market_data_pipeline(db_manager: DatabaseManager, coingecko_client: CoinGeckoClient):
    """Ğ˜Ğ·Ğ¿ÑŠĞ»Ğ½ÑĞ²Ğ° Ğ¿Ñ€Ğ¾Ñ†ĞµÑĞ° Ğ¿Ğ¾ ÑÑŠĞ±Ğ¸Ñ€Ğ°Ğ½Ğµ Ğ½Ğ° Ğ¿Ğ°Ğ·Ğ°Ñ€Ğ½Ğ¸ Ğ´Ğ°Ğ½Ğ½Ğ¸ Ğ¾Ñ‚ CoinGecko."""
    print("\n--- ğŸ“ˆ STEP 3: COLLECTING COINGECKO MARKET DATA ---")
    for asset_name, asset_id in ASSETS_TO_TRACK.items():
        print(f"Processing market data for '{asset_name}'...")

        last_date_str = db_manager.get_latest_market_data_date(asset_id)
        days_to_fetch = 30  # Ğ¡Ñ‚Ğ¾Ğ¹Ğ½Ğ¾ÑÑ‚ Ğ¿Ğ¾ Ğ¿Ğ¾Ğ´Ñ€Ğ°Ğ·Ğ±Ğ¸Ñ€Ğ°Ğ½Ğµ

        if last_date_str:
            last_date = datetime.strptime(last_date_str, '%Y-%m-%d')
            days_diff = (datetime.now() - last_date).days
            if days_diff > 0:
                days_to_fetch = days_diff
                print(f"   -> Last data is from {days_diff} days ago. Fetching new data.")
            else:
                print("   -> Market data is up to date. Skipping.")
                continue # ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ°Ğ¼Ğµ Ğ¾ÑÑ‚Ğ°Ğ½Ğ°Ğ»Ğ°Ñ‚Ğ° Ñ‡Ğ°ÑÑ‚ Ğ¾Ñ‚ Ñ†Ğ¸ĞºÑŠĞ»Ğ° Ğ·Ğ° Ñ‚Ğ¾Ğ·Ğ¸ Ğ°ĞºÑ‚Ğ¸Ğ²
        else:
            print(f"   -> No existing data. Fetching initial {days_to_fetch} days of data.")

        # --- Ğ¢ĞĞ’Ğ Ğ• ĞšĞĞ Ğ•ĞšĞ¦Ğ˜Ğ¯Ğ¢Ğ ---
        # Ğ¢ĞµĞ·Ğ¸ Ğ´Ğ²Ğ° Ñ€ĞµĞ´Ğ° ÑĞ° Ğ¿Ñ€ĞµĞ¼ĞµÑÑ‚ĞµĞ½Ğ¸ ĞĞĞ’ĞªĞ¢Ğ Ğ•, Ğ·Ğ° Ğ´Ğ° ÑĞ° Ñ‡Ğ°ÑÑ‚ Ğ¾Ñ‚ for Ñ†Ğ¸ĞºÑŠĞ»Ğ°.
        market_data = coingecko_client.fetch_historical_data(asset_id, days=days_to_fetch)
        if market_data:
            rows_saved = db_manager.save_market_data(market_data)
            print(f"   -> ğŸ’¾ Saved {rows_saved} new market data records.")

def run_kucoin_historical_data_pipeline(db_manager: DatabaseManager, kucoin_handler: KucoinHandler):
    """Ğ˜Ğ·Ğ¿ÑŠĞ»Ğ½ÑĞ²Ğ° Ğ¿Ñ€Ğ¾Ñ†ĞµÑĞ° Ğ¿Ğ¾ ÑÑŠĞ±Ğ¸Ñ€Ğ°Ğ½Ğµ Ğ½Ğ° Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ´Ğ°Ğ½Ğ½Ğ¸ (ÑĞ²ĞµÑ‰Ğ¸) Ğ¾Ñ‚ KuCoin."""
    print("\n--- ğŸ’¹ STEP 4: COLLECTING KUCOIN HISTORICAL DATA ---")
    # ... (ĞºĞ¾Ğ´ÑŠÑ‚ Ñ‚ÑƒĞº Ğ¾ÑÑ‚Ğ°Ğ²Ğ° ÑÑŠÑ‰Ğ¸ÑÑ‚) ...
    kucoin_symbols = ['BTC-USDT', 'ETH-USDT'] 
    end_date = datetime.now()
    start_date = end_date - timedelta(days=30)
    end_date_str = end_date.strftime('%Y-%m-%d')
    start_date_str = start_date.strftime('%Y-%m-%d')
    for symbol in kucoin_symbols:
        print(f"Processing KuCoin historical data for '{symbol}'...")
        historical_data = kucoin_handler.get_historical_data(symbol, start_date_str, end_date_str)
        if historical_data:
            print(f"  -> Fetched {len(historical_data)} records. Saving to database...")
            db_manager.save_historical_prices(symbol, historical_data)
        else:
            print(f"  -> No historical data received from KuCoin for {symbol}. Skipping.")

# --- ĞĞĞ’Ğ PIPELINE Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ¯: Ğ—Ğ° DefiLlama Ğ´Ğ°Ğ½Ğ½Ğ¸ ---
def run_defillama_pipeline(db_manager: DatabaseManager, defillama_handler: DefiLlamaHandler):
    """
    Ğ˜Ğ·Ğ¿ÑŠĞ»Ğ½ÑĞ²Ğ° Ğ¿Ñ€Ğ¾Ñ†ĞµÑĞ° Ğ¿Ğ¾ ÑÑŠĞ±Ğ¸Ñ€Ğ°Ğ½Ğµ Ğ½Ğ° on-chain TVL Ğ´Ğ°Ğ½Ğ½Ğ¸ Ğ¾Ñ‚ DefiLlama.
    """
    print("\n--- ğŸ”— STEP 5: COLLECTING DEFI LLAMA ON-CHAIN DATA ---")
    
    # Ğ”ĞµÑ„Ğ¸Ğ½Ğ¸Ñ€Ğ°Ğ¼Ğµ ĞºĞ¾Ğ¸ Ğ¼Ñ€ĞµĞ¶Ğ¸ Ğ¸ÑĞºĞ°Ğ¼Ğµ Ğ´Ğ° ÑĞ»ĞµĞ´Ğ¸Ğ¼
    chains_to_track = ["Ethereum", "Solana", "Arbitrum", "Polygon"]
    
    # 1. Ğ˜Ğ·Ğ²Ğ»Ğ¸Ñ‡Ğ°Ğ¼Ğµ Ğ´Ğ°Ğ½Ğ½Ğ¸Ñ‚Ğµ Ğ¾Ñ‚ DefiLlama
    tvl_data = defillama_handler.get_chains_tvl(chains_to_track)
    
    # 2. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞ²Ğ°Ğ¼Ğµ Ğ¸ Ğ·Ğ°Ğ¿Ğ¸ÑĞ²Ğ°Ğ¼Ğµ Ğ² Ğ±Ğ°Ğ·Ğ°Ñ‚Ğ° Ğ´Ğ°Ğ½Ğ½Ğ¸
    if tvl_data:
        print(f"  -> Fetched TVL data for {len(tvl_data)} chains. Saving to database...")
        db_manager.save_chain_tvl_data(tvl_data)
    else:
        print(f"  -> No TVL data received from DefiLlama. Skipping.")

def main():
    """Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ‚Ğ° Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ, ĞºĞ¾ÑÑ‚Ğ¾ Ğ´Ğ¸Ñ€Ğ¸Ğ¶Ğ¸Ñ€Ğ° Ñ†ĞµĞ»Ğ¸Ñ Ğ¿Ñ€Ğ¾Ñ†ĞµÑ."""
    print("ğŸš€ğŸš€ğŸš€ ORBITRON AI - STARTING FULL PIPELINE ğŸš€ğŸš€ğŸš€")

    # --- ĞĞ‘ĞĞĞ’Ğ•ĞĞ Ğ˜ĞĞ˜Ğ¦Ğ˜ĞĞ›Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯ ---
    db_manager = DatabaseManager()
    news_api_client = NewsApiClient()
    coingecko_client = CoinGeckoClient()
    ai_analyzer = AIAnalyzer()
    kucoin_handler = KucoinHandler()
    defillama_handler = DefiLlamaHandler() # Ğ”Ğ¾Ğ±Ğ°Ğ²ÑĞ¼Ğµ DefiLlama

    # --- Ğ˜Ğ—ĞŸĞªĞ›ĞĞ•ĞĞ˜Ğ• ĞĞ Ğ’Ğ¡Ğ˜Ğ§ĞšĞ˜ Ğ¡Ğ¢ĞªĞŸĞšĞ˜ ---
    run_news_pipeline(db_manager, news_api_client)
    run_ai_analysis_pipeline(db_manager, ai_analyzer)
    run_market_data_pipeline(db_manager, coingecko_client)
    run_kucoin_historical_data_pipeline(db_manager, kucoin_handler)
    run_defillama_pipeline(db_manager, defillama_handler) # Ğ”Ğ¾Ğ±Ğ°Ğ²ÑĞ¼Ğµ Ğ½Ğ¾Ğ²Ğ°Ñ‚Ğ° ÑÑ‚ÑŠĞ¿ĞºĞ°

    print("\nğŸğŸğŸ PIPELINE FINISHED SUCCESSFULLY! ğŸğŸğŸ")


if __name__ == "__main__":
    main()